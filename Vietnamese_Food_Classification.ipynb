{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPWkmFZexsAtWLhKhiThja2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"avw--sGsvNN2","executionInfo":{"status":"error","timestamp":1736320206122,"user_tz":-420,"elapsed":118495,"user":{"displayName":"Michael Ha","userId":"05310127525331572955"}},"outputId":"9c5dc849-e891-40bc-d015-5ca016795672"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.5)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.67.1)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.12.14)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n","Downloading from https://www.kaggle.com/api/v1/datasets/download/quandang/vietnamese-foods?dataset_version_number=11...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.17G/4.17G [00:41<00:00, 109MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/quandang/vietnamese-foods/versions/11\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/root/.cache/kagglehub/datasets/quandang/vietnamese-foods/versions/11/train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7c6c03bfd4f8>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_paths_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_paths_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_paths_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-7c6c03bfd4f8>\u001b[0m in \u001b[0;36mload_image_paths_and_labels\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure consistent class order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.cache/kagglehub/datasets/quandang/vietnamese-foods/versions/11/train'"]}],"source":["# Install required libraries\n","!pip install kagglehub opencv-python-headless tensorflow\n","\n","# Import necessary libraries\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.models import Model\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.preprocessing import normalize\n","import cv2\n","\n","# Download the dataset using KaggleHub\n","import kagglehub\n","\n","# Download dataset\n","path = kagglehub.dataset_download(\"quandang/vietnamese-foods\")\n","print(\"Path to dataset files:\", path)\n","\n","# Set dataset paths\n","train_path = os.path.join(path, \"train\")\n","val_path = os.path.join(path, \"validation\")\n","test_path = os.path.join(path, \"test\")\n","\n","# Load image paths and labels\n","def load_image_paths_and_labels(base_path):\n","    image_paths = []\n","    labels = []\n","    classes = sorted(os.listdir(base_path))  # Ensure consistent class order\n","    for label, class_name in enumerate(classes):\n","        class_path = os.path.join(base_path, class_name)\n","        for img_name in os.listdir(class_path):\n","            image_paths.append(os.path.join(class_path, img_name))\n","            labels.append(label)\n","    return image_paths, labels, classes\n","\n","train_images, train_labels, class_names = load_image_paths_and_labels(train_path)\n","val_images, val_labels, _ = load_image_paths_and_labels(val_path)\n","test_images, test_labels, _ = load_image_paths_and_labels(test_path)\n","\n","print(f\"Number of training images: {len(train_images)}\")\n","print(f\"Number of validation images: {len(val_images)}\")\n","print(f\"Number of test images: {len(test_images)}\")\n","print(f\"Classes: {class_names}\")\n","\n","# Define image preprocessing function\n","IMG_SIZE = (224, 224)\n","\n","def preprocess_image(image_path):\n","    img = load_img(image_path, target_size=IMG_SIZE)\n","    img_array = img_to_array(img) / 255.0\n","    return np.expand_dims(img_array, axis=0)\n","\n","# Load pre-trained model for feature extraction\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n","model = Model(inputs=base_model.input, outputs=tf.keras.layers.GlobalAveragePooling2D()(base_model.output))\n","\n","# Extract features from images\n","def extract_features(image_paths, model):\n","    features = []\n","    for image_path in image_paths:\n","        img = preprocess_image(image_path)\n","        feature = model.predict(img, verbose=0)\n","        features.append(feature[0])\n","    return np.array(features)\n","\n","# Extract features for train, validation, and test sets\n","print(\"Extracting features...\")\n","train_features = extract_features(train_images, model)\n","val_features = extract_features(val_images, model)\n","test_features = extract_features(test_images, model)\n","print(\"Feature extraction complete.\")\n","\n","# Normalize the features for similarity calculation\n","train_features = normalize(train_features, axis=1)\n","\n","# Image retrieval function\n","def retrieve_similar_images(query_image_path, model, train_features, train_images, top_k=5):\n","    query_feature = model.predict(preprocess_image(query_image_path))[0]\n","    query_feature = normalize(query_feature.reshape(1, -1), axis=1)\n","    similarities = cosine_similarity(query_feature, train_features)\n","    top_indices = np.argsort(similarities[0])[::-1][:top_k]\n","    return [train_images[i] for i in top_indices], similarities[0][top_indices]\n","\n","# Visualization function\n","def visualize_results(query_image_path, similar_image_paths, similarities):\n","    plt.figure(figsize=(15, 5))\n","\n","    # Query image\n","    plt.subplot(1, len(similar_image_paths) + 1, 1)\n","    query_img = cv2.cvtColor(cv2.imread(query_image_path), cv2.COLOR_BGR2RGB)\n","    plt.imshow(query_img)\n","    plt.title(\"Query Image\")\n","    plt.axis(\"off\")\n","\n","    # Retrieved images\n","    for i, (img_path, sim) in enumerate(zip(similar_image_paths, similarities)):\n","        plt.subplot(1, len(similar_image_paths) + 1, i + 2)\n","        retrieved_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n","        plt.imshow(retrieved_img)\n","        plt.title(f\"Sim: {sim:.2f}\")\n","        plt.axis(\"off\")\n","    plt.show()\n","\n","# Test the image retrieval system\n","query_image = test_images[0]  # Use the first test image as query\n","similar_images, similarity_scores = retrieve_similar_images(query_image, model, train_features, train_images)\n","\n","# Visualize results\n","visualize_results(query_image, similar_images, similarity_scores)\n"]}]}